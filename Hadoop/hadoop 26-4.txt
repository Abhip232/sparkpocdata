  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information


-rw-r--r--   1 hduser supergroup          0 2022-04-25 19:03 student/_SUCCESS
-rw-r--r--   1 hduser supergroup         17 2022-04-25 19:03 student/part-m-00000
-rw-r--r--   1 hduser supergroup         14 2022-04-25 19:03 student/part-m-00001
-rw-r--r--   1 hduser supergroup         13 2022-04-25 19:03 student/part-m-00002
-rw-r--r--   1 hduser supergroup         16 2022-04-25 19:03 student/part-m-00003

===================cloudera============

[cloudera@quickstart ~]$ sqoop list-databases --connect jdbc:mysql://quickstart.cloudera --username root -P
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
22/04/25 20:39:38 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5-cdh5.4.0
Enter password: 
22/04/25 20:39:41 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
information_schema
BTM
cm
firehose
hue
metastore
mysql
oozie
practice
retail_db
sentry
[cloudera@quickstart ~]$ sqoop list-tables --connect jdbc:mysql://quickstart.cloudera/retail_db --username root -P
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
22/04/25 20:41:18 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5-cdh5.4.0
Enter password: 
22/04/25 20:41:22 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
categories
customers
departments
order_items
orders
products
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --username root -P
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
22/04/25 20:44:55 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5-cdh5.4.0
Enter password: 
22/04/25 20:44:58 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
22/04/25 20:44:58 INFO tool.CodeGenTool: Beginning code generation
22/04/25 20:44:59 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `categories` AS t LIMIT 1
22/04/25 20:44:59 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `categories` AS t LIMIT 1
22/04/25 20:44:59 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/2d634d3dd398f693987bdb38803c1663/categories.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
22/04/25 20:45:01 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/2d634d3dd398f693987bdb38803c1663/categories.jar
22/04/25 20:45:01 WARN manager.MySQLManager: It looks like you are importing from mysql.
22/04/25 20:45:01 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
22/04/25 20:45:01 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
22/04/25 20:45:01 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
22/04/25 20:45:01 INFO mapreduce.ImportJobBase: Beginning import of categories
22/04/25 20:45:01 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
22/04/25 20:45:02 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
22/04/25 20:45:03 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
22/04/25 20:45:03 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
22/04/25 20:45:05 INFO db.DBInputFormat: Using read commited transaction isolation
22/04/25 20:45:05 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`category_id`), MAX(`category_id`) FROM `categories`
22/04/25 20:45:05 INFO mapreduce.JobSubmitter: number of splits:4
22/04/25 20:45:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1650943246170_0002
22/04/25 20:45:06 INFO impl.YarnClientImpl: Submitted application application_1650943246170_0002
22/04/25 20:45:06 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1650943246170_0002/
22/04/25 20:45:06 INFO mapreduce.Job: Running job: job_1650943246170_0002
22/04/25 20:45:14 INFO mapreduce.Job: Job job_1650943246170_0002 running in uber mode : false
22/04/25 20:45:14 INFO mapreduce.Job:  map 0% reduce 0%
22/04/25 20:45:25 INFO mapreduce.Job:  map 50% reduce 0%
22/04/25 20:45:26 INFO mapreduce.Job:  map 75% reduce 0%
22/04/25 20:45:27 INFO mapreduce.Job:  map 100% reduce 0%
22/04/25 20:45:27 INFO mapreduce.Job: Job job_1650943246170_0002 completed successfully
22/04/25 20:45:28 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=541740
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=472
		HDFS: Number of bytes written=1029
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=33026
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=33026
		Total vcore-seconds taken by all map tasks=33026
		Total megabyte-seconds taken by all map tasks=33818624
	Map-Reduce Framework
		Map input records=58
		Map output records=58
		Input split bytes=472
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=442
		CPU time spent (ms)=4660
		Physical memory (bytes) snapshot=693911552
		Virtual memory (bytes) snapshot=6265507840
		Total committed heap usage (bytes)=570425344
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1029
22/04/25 20:45:28 INFO mapreduce.ImportJobBase: Transferred 1.0049 KB in 24.9742 seconds (41.2026 bytes/sec)
22/04/25 20:45:28 INFO mapreduce.ImportJobBase: Retrieved 58 records.
[cloudera@quickstart ~]$ hdfs dfs -ls 
Found 13 items
drwxr-xr-x   - cloudera cloudera          0 2019-12-29 00:57 _sqoop
drwxr-xr-x   - cloudera cloudera          0 2022-04-23 04:35 avd
drwxr-xr-x   - cloudera cloudera          0 2022-04-23 04:30 avd5
drwxr-xr-x   - cloudera cloudera          0 2019-06-26 01:29 bank
drwxr-xr-x   - cloudera cloudera          0 2019-06-29 06:38 btm
drwxr-xr-x   - cloudera cloudera          0 2022-04-25 20:45 categories
-rw-r--r--   3 cloudera cloudera        275 2018-03-11 01:47 emp
drwxr-xr-x   - cloudera cloudera          0 2018-03-02 02:56 input
drwxr-xr-x   - cloudera cloudera          0 2017-03-02 18:13 spark
drwxr-xr-x   - cloudera cloudera          0 2018-08-24 09:57 spark_data
-rw-r--r--   1 cloudera cloudera         36 2018-03-02 01:58 spark_inp
drwxr-xr-x   - cloudera cloudera          0 2018-07-15 02:03 sparklab
drwxr-xr-x   - cloudera cloudera          0 2018-07-14 21:54 test
[cloudera@quickstart ~]$ hdfs dfs -ls categories
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2022-04-25 20:45 categories/_SUCCESS
-rw-r--r--   1 cloudera cloudera        271 2022-04-25 20:45 categories/part-m-00000
-rw-r--r--   1 cloudera cloudera        263 2022-04-25 20:45 categories/part-m-00001
-rw-r--r--   1 cloudera cloudera        266 2022-04-25 20:45 categories/part-m-00002
-rw-r--r--   1 cloudera cloudera        229 2022-04-25 20:45 categories/part-m-00003
[cloudera@quickstart ~]$ hdfs dfs -cat categories/part-m-*
1,2,Football
2,2,Soccer
3,2,Baseball & Softball
4,2,Basketball
5,2,Lacrosse
6,2,Tennis & Racquet
7,2,Hockey
8,2,More Sports
9,3,Cardio Equipment
10,3,Strength Training
11,3,Fitness Accessories
12,3,Boxing & MMA
13,3,Electronics
14,3,Yoga & Pilates
15,3,Training by Sport
16,3,As Seen on  TV!
17,4,Cleats
18,4,Men's Footwear
19,4,Women's Footwear
20,4,Kids' Footwear
21,4,Featured Shops
22,4,Accessories
23,5,Men's Apparel
24,5,Women's Apparel
25,5,Boys' Apparel
26,5,Girls' Apparel
27,5,Accessories
28,5,Top Brands
29,5,Shop By Sport
30,6,Men's Golf Clubs
31,6,Women's Golf Clubs
32,6,Golf Apparel
33,6,Golf Shoes
34,6,Golf Bags & Carts
35,6,Golf Gloves
36,6,Golf Balls
37,6,Electronics
38,6,Kids' Golf Clubs
39,6,Team Shop
40,6,Accessories
41,6,Trade-In
42,7,Bike & Skate Shop
43,7,Camping & Hiking
44,7,Hunting & Shooting
45,7,Fishing
46,7,Indoor/Outdoor Games
47,7,Boating
48,7,Water Sports
49,8,MLB
50,8,NFL
51,8,NHL
52,8,NBA
53,8,NCAA
54,8,MLS
55,8,International Soccer
56,8,World Cup Shop
57,8,MLB Players
58,8,NFL Players
[cloudera@quickstart ~]$ sqoop list-tables --connect jdbc:mysql://quickstart.cloudera/retail_db --username root -P
[cloudera@quickstart ~]$ sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --target -dir /sqoopjob1 --username root -P
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
22/04/25 20:47:40 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5-cdh5.4.0
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Error parsing arguments for import:
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: --target
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: -dir
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: /sqoopjob1
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: --username
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: root
22/04/25 20:47:40 ERROR tool.BaseSqoopTool: Unrecognized argument: -P

Try --help for usage instructions.
[cloudera@quickstart ~]$ sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --target-dir /sqoopjob1 --username root -P
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
22/04/25 20:48:13 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5-cdh5.4.0
Enter password: 
22/04/25 20:48:19 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
22/04/25 20:48:19 INFO tool.CodeGenTool: Beginning code generation
22/04/25 20:48:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `categories` AS t LIMIT 1
22/04/25 20:48:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `categories` AS t LIMIT 1
22/04/25 20:48:20 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/9c8aec21ddbff1609da82eea5f8ae491/categories.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
22/04/25 20:48:22 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/9c8aec21ddbff1609da82eea5f8ae491/categories.jar
22/04/25 20:48:22 WARN manager.MySQLManager: It looks like you are importing from mysql.
22/04/25 20:48:22 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
22/04/25 20:48:22 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
22/04/25 20:48:22 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
22/04/25 20:48:22 INFO mapreduce.ImportJobBase: Beginning import of categories
22/04/25 20:48:22 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
22/04/25 20:48:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
22/04/25 20:48:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
22/04/25 20:48:23 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
22/04/25 20:48:24 INFO db.DBInputFormat: Using read commited transaction isolation
22/04/25 20:48:24 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`category_id`), MAX(`category_id`) FROM `categories`
22/04/25 20:48:24 INFO mapreduce.JobSubmitter: number of splits:4
22/04/25 20:48:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1650943246170_0003
22/04/25 20:48:25 INFO impl.YarnClientImpl: Submitted application application_1650943246170_0003
22/04/25 20:48:25 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1650943246170_0003/
22/04/25 20:48:25 INFO mapreduce.Job: Running job: job_1650943246170_0003
22/04/25 20:48:32 INFO mapreduce.Job: Job job_1650943246170_0003 running in uber mode : false
22/04/25 20:48:32 INFO mapreduce.Job:  map 0% reduce 0%
22/04/25 20:48:38 INFO mapreduce.Job:  map 25% reduce 0%
22/04/25 20:48:39 INFO mapreduce.Job:  map 50% reduce 0%
22/04/25 20:48:40 INFO mapreduce.Job:  map 75% reduce 0%
22/04/25 20:48:41 INFO mapreduce.Job:  map 100% reduce 0%
22/04/25 20:48:41 INFO mapreduce.Job: Job job_1650943246170_0003 completed successfully
22/04/25 20:48:41 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=542244
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=472
		HDFS: Number of bytes written=1029
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=18814
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=18814
		Total vcore-seconds taken by all map tasks=18814
		Total megabyte-seconds taken by all map tasks=19265536
	Map-Reduce Framework
		Map input records=58
		Map output records=58
		Input split bytes=472
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=213
		CPU time spent (ms)=4120
		Physical memory (bytes) snapshot=725876736
		Virtual memory (bytes) snapshot=6282125312
		Total committed heap usage (bytes)=635961344
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1029
22/04/25 20:48:41 INFO mapreduce.ImportJobBase: Transferred 1.0049 KB in 18.8439 seconds (54.6065 bytes/sec)
22/04/25 20:48:41 INFO mapreduce.ImportJobBase: Retrieved 58 records.
[cloudera@quickstart ~]$ hdfs dfs -ls /
Found 7 items
drwxr-xr-x   - cloudera supergroup          0 2019-06-26 01:46 /bank
drwxr-xr-x   - hbase    supergroup          0 2022-04-25 20:20 /hbase
drwxr-xr-x   - solr     solr                0 2015-04-23 07:49 /solr
drwxr-xr-x   - cloudera supergroup          0 2022-04-25 20:48 /sqoopjob1
drwxrwxrwx   - hdfs     supergroup          0 2016-12-16 23:21 /tmp
drwxr-xr-x   - hdfs     supergroup          0 2018-08-24 10:10 /user
drwxr-xr-x   - hdfs     supergroup          0 2015-04-23 07:47 /var
[cloudera@quickstart ~]$ hdfs dfs -ls /sqoopjob1
Found 5 items
-rw-r--r--   1 cloudera supergroup          0 2022-04-25 20:48 /sqoopjob1/_SUCCESS
-rw-r--r--   1 cloudera supergroup        271 2022-04-25 20:48 /sqoopjob1/part-m-00000
-rw-r--r--   1 cloudera supergroup        263 2022-04-25 20:48 /sqoopjob1/part-m-00001
-rw-r--r--   1 cloudera supergroup        266 2022-04-25 20:48 /sqoopjob1/part-m-00002
-rw-r--r--   1 cloudera supergroup        229 2022-04-25 20:48 /sqoopjob1/part-m-00003
[cloudera@quickstart ~]$ 

===============================================================================================
28  hadoop version
  729  clear
  730  hadoop fs 
  731  clear
  732  hadoop fs -ls /
  733  hadoop fs -mkdir avd
  734  hadoop fs -ls /
  735  hadoop fs -ls /user
  736  hadoop fs -ls /user/cloudera
  737  clear
  738  pwd
  739  sudo vi samplefile
  740  ls -ltr
  741  clear
  742  hadoop fs -put /home/cloudera/samplefile avd
  743  hadoop fs -lsr avd
  744  hadoop fs -cat avd/samplefile
  745  history
  746  c
  747  sudo jps
  748  hadoop
  749  hadoop version
  750  hadoop fs
  751  hadoop fs -ls
  752  hadoop fs -ls /
  753  hadoop fs mkdir avd
  754  hadoop fs -mkdir avd
  755  hadoop fs -mkdir avd5
  756  hadoop fs -ls/
  757  hadoop fs -ls /
  758  hadoop fs -ls /user
  759  hadoop fs -ls /user/cloudera
  760  pwd
  761  cd ..
  762  pwd
  763  sudo vi samplefile
  764  sudo vi deepsample
  765  ls -ltr
  766  hadoop fs -put /home/clouders/deepsample avd
  767  hadoop fs -put /home/cloudera/deepsample avd
  768  hadoop fs -lsr avd
  769  hadoop fs -cat avd/deepsample
  770  hadoop fs -cat avd/samplefile
  771  sqoop list-databases --connect jdbc:mysql://quickstart.cloudera --username root -P
  772  sqoop list-tables --connect jdbc:mysql://quickstart.cloudera/retail_db --username root -P
  773  sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --username root -P
  774  hdfs dfs -ls 
  775  hdfs dfs -ls categories
  776  hdfs dfs -cat categories/part-m-*
  777  sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --target -dir /sqoopjob1 --username root -P
  778  sqoop import --connect jdbc:mysql://quickstart.cloudera/retail_db --table categories --target-dir /sqoopjob1 --username root -P
  779  hdfs dfs -ls /
  780  hdfs dfs -ls /sqoopjob1
  781  history
[cloudera@quickst
